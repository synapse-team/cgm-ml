{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train PointNet (https://arxiv.org/abs/1612.00593).\n",
    "\n",
    "This notebook shows you how to use the PreprocessedDataGenerator in order to train PointNet.\n",
    "\n",
    "The PreprocessedDataGenerator uses preprocessed-data instead of ETL-data. Wheras ETL-data comes mainly as PCD-files, preprocessed-data comes mainly as pointclouds stored as numpy-arrays. We identified PCD-loading as a bottleneck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset path.\n",
    "\n",
    "This snippet shows you how to get the lates preprocessed path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgmcore.preprocesseddatagenerator import get_dataset_path\n",
    "dataset_path = \"../../data/preprocessed/2018_10_31_14_19_42\"\n",
    "print(\"Using dataset path\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lying = [\"SAM-GOV-002\", \"SAM-GOV-045\", \"SAM-GOV-051\", \"SAM-GOV-052\", \"SAM-GOV-063\", \"SAM-GOV-068\", \"SAM-GOV-072\", \"SAM-GOV-082\", \"SAM-GOV-088\", \"SAM-GOV-097\", \"SAM-SNG-052\", \"SAM-SNG-065\", \"MH_WHH_0004\", \"MH_WHH_0028\", \"MH_WHH_0032\", \"MH_WHH_0035\", \"MH_WHH_0042\", \"MH_WHH_0047\", \"MH_WHH_0056\", \"MH_WHH_0152\", \"MH_WHH_0161\", \"MH_WHH_0173\", \"MH_WHH_0187\", \"MH_WHH_2909\", \"MH_WHH_2926\", \"MH_WHH_2930\", \"MH_WHH_2960\", \"MH_WHH_2994\", \"MP_WHH_0031\", \"MP_WHH_0035\", \"MP_WHH_0036\", \"MP_WHH_0037\", \"MP_WHH_0038\", \"MP_WHH_0044\", \"MP_WHH_0048\", \"MP_WHH_0061\", \"MP_WHH_0063\", \"MP_WHH_0101\", \"MP_WHH_0133\", \"MP_WHH_0147\", \"MP_WHH_0150\", \"MP_WHH_0153\", \"MP_WHH_0280\", \"MP_WHH_0282\", \"MP_WHH_0285\", \"MP_WHH_0292\", \"MP_WHH_2608\", \"MP_WHH_2612\", \"MP_WHH_2618\", \"MP_WHH_2619\", \"MP_WHH_2651\", \"MP_WHH_2656\", \"MP_WHH_2667\", \"MP_WHH_2676\", \"MP_WHH_2677\", \"MP_WHH_2696\", \"MP_WHH_2697\", \"MP_WHH_2714\", \"MP_WHH_2716\", \"MP_WHH_2718\", \"MP_WHH_2725\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 20\n",
    "validation_steps = 10\n",
    "epochs = 15\n",
    "batch_size = 100\n",
    "random_seed = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data-generator.\n",
    "\n",
    "The method create_datagenerator_from_parameters is a convencience method. It allows you to instantiate a generator from a specification-dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgmcore.preprocesseddatagenerator import create_datagenerator_from_parameters\n",
    "\n",
    "dataset_parameters_pointclouds = {}\n",
    "dataset_parameters_pointclouds[\"input_type\"] = \"pointcloud\"\n",
    "dataset_parameters_pointclouds[\"output_targets\"] = [\"height\"]\n",
    "dataset_parameters_pointclouds[\"random_seed\"] = random_seed\n",
    "dataset_parameters_pointclouds[\"pointcloud_target_size\"] = 1000\n",
    "dataset_parameters_pointclouds[\"pointcloud_random_rotation\"] = False\n",
    "dataset_parameters_pointclouds[\"sequence_length\"] = 0\n",
    "datagenerator_instance_pointclouds = create_datagenerator_from_parameters(dataset_path, dataset_parameters_pointclouds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the QR-Codes and do a train-validate-split.\n",
    "\n",
    "The data-generator is perfectly capable of retrieving all QR-codes from the dataset. This snipped shows how to do so and how to split the QR-codes into two sets: Train and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the QR-codes.\n",
    "qrcodes_to_use = datagenerator_instance_pointclouds.qrcodes[0:1500]\n",
    "\n",
    "qrcodes_standing = []\n",
    "for qrcode in qrcodes_to_use:\n",
    "    if qrcode not in lying:\n",
    "        qrcodes_standing.append(qrcode)\n",
    "\n",
    "qrcodes_to_use = qrcodes_standing\n",
    "\n",
    "# Do the split.\n",
    "random.seed(random_seed)\n",
    "qrcodes_shuffle = qrcodes_to_use[:]\n",
    "random.shuffle(qrcodes_shuffle)\n",
    "split_index = int(0.7 * len(qrcodes_shuffle))\n",
    "split_index_1 = int(0.9 * len(qrcodes_shuffle))\n",
    "qrcodes_train = sorted(qrcodes_shuffle[:split_index])\n",
    "qrcodes_validate = sorted(qrcodes_shuffle[split_index:split_index_1])\n",
    "qrcodes_test = sorted(qrcodes_shuffle[split_index_1:])\n",
    "del qrcodes_shuffle\n",
    "#print(\"QR-codes for training:\\n\", \"\\t\".join(qrcodes_train))\n",
    "#print(\"QR-codes for validation:\\n\", \"\\t\".join(qrcodes_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating python generators for training and validation.\n",
    "\n",
    "Now both QR-codes lists can be used for creating the actual generators. One for training and one for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create python generators.\n",
    "generator_pointclouds_train = datagenerator_instance_pointclouds.generate(size=batch_size, qrcodes_to_use=qrcodes_train)\n",
    "generator_pointclouds_validate = datagenerator_instance_pointclouds.generate(size=batch_size, qrcodes_to_use=qrcodes_validate)\n",
    "generator_pointclouds_test = datagenerator_instance_pointclouds.generate(size=batch_size, qrcodes_to_use=qrcodes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the generator to create data manually.\n",
    "\n",
    "Of course you can use the generator to create data manually anytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = next(generator_pointclouds_train)\n",
    "print(\"Input-shape:\", train_x.shape)\n",
    "print(\"Output-shape:\", train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-details.\n",
    "\n",
    "Training-details are a dictionary that gets stored in a file after training. It is supposed to contain information that is valuable. For example data that is relevant for training including the hyper-parameters. Intended to be used when comparing different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_details = {\n",
    "    \"dataset_path\" : dataset_path,\n",
    "    \"qrcodes_train\" : qrcodes_train,\n",
    "    \"qrcodes_validate\" : qrcodes_validate,\n",
    "    \"steps_per_epoch\" : steps_per_epoch,\n",
    "    \"validation_steps\" : validation_steps,\n",
    "    \"epochs\" : epochs,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"random_seed\" : random_seed,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PointNet.\n",
    "\n",
    "The module modelutils contains methods for creating Neural Nets. The following code shows how to instantiate and train PointNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_point_net(input_shape, output_size, hidden_sizes = [512, 256]):\n",
    "    \"\"\"\n",
    "    Creates a PointNet.\n",
    "\n",
    "    See https://github.com/garyloveavocado/pointnet-keras/blob/master/train_cls.py\n",
    "\n",
    "    Args:\n",
    "        input_shape (shape): Input-shape.\n",
    "        output_size (int): Output-size.\n",
    "\n",
    "    Returns:\n",
    "        Model: A model.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"input shape: \", input_shape)\n",
    "    num_points = input_shape[0]\n",
    "\n",
    "    def mat_mul(A, B):\n",
    "        result = tf.matmul(A, B)\n",
    "        return result\n",
    "\n",
    "    input_points = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(64, 1, activation='relu',\n",
    "                      input_shape=input_shape)(input_points)\n",
    "    #x = layers.Convolution1D(64, 1, activation='relu',\n",
    "    #                  input_shape=input_shape)(input_points)\n",
    "    # Convolution1D(nb_filter, filter_length, activation=None, input_dim=None, input_length=None)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Convolution1D(128, 1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Convolution1D(1024, 1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=num_points)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
    "    input_T = layers.Reshape((3, 3))(x)\n",
    "\n",
    "    # forward net\n",
    "    g = layers.Lambda(mat_mul, arguments={'B': input_T})(input_points)\n",
    "    g = layers.Convolution1D(64, 1, input_shape=input_shape, activation='relu')(g)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "    g = layers.Convolution1D(64, 1, input_shape=input_shape, activation='relu')(g)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "\n",
    "    # feature transform net\n",
    "    f = layers.Convolution1D(64, 1, activation='relu')(g)\n",
    "    f = layers.BatchNormalization()(f)\n",
    "    f = layers.Convolution1D(128, 1, activation='relu')(f)\n",
    "    f = layers.BatchNormalization()(f)\n",
    "    f = layers.Convolution1D(1024, 1, activation='relu')(f)\n",
    "    f = layers.BatchNormalization()(f)\n",
    "    f = layers.MaxPooling1D(pool_size=num_points)(f)\n",
    "    f = layers.Dense(512, activation='relu')(f)\n",
    "    f = layers.BatchNormalization()(f)\n",
    "    f = layers.Dense(256, activation='relu')(f)\n",
    "    f = layers.BatchNormalization()(f)\n",
    "    f = layers.Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
    "    feature_T = layers.Reshape((64, 64))(f)\n",
    "\n",
    "    # forward net\n",
    "    g = layers.Lambda(mat_mul, arguments={'B': feature_T})(g)\n",
    "    g = layers.Convolution1D(64, 1, activation='relu')(g)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "    g = layers.Convolution1D(128, 1, activation='relu')(g)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "    g = layers.Convolution1D(1024, 1, activation='relu')(g)\n",
    "    g = layers.BatchNormalization()(g)\n",
    "\n",
    "    # global_feature\n",
    "    global_feature = layers.MaxPooling1D(pool_size=num_points)(g)\n",
    "\n",
    "    # point_net_cls\n",
    "    c = global_feature\n",
    "    for hidden_size in hidden_sizes:\n",
    "        c = layers.Dense(hidden_size, activation='relu')(c)\n",
    "        c = layers.BatchNormalization()(c)\n",
    "        c = layers.Dropout(rate=0.7)(c)\n",
    "    \n",
    "    c = layers.Dense(output_size, activation='linear')(c)\n",
    "    prediction = layers.Flatten()(c)\n",
    "\n",
    "    model = models.Model(inputs=input_points, outputs=prediction)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cgmcore import modelutils\n",
    "from keras import optimizers\n",
    "\n",
    "input_shape = (dataset_parameters_pointclouds[\"pointcloud_target_size\"], 3)\n",
    "output_size = 1\n",
    "model_pointnet = create_point_net(input_shape, output_size, hidden_sizes = [64])\n",
    "model_pointnet.summary()\n",
    "\n",
    "sgdl = [(0.0001, 1e-6, 0.2, True), (0.0001, 1e-6, 0.4, True),\n",
    "        (0.0001, 1e-6, 0.6, True), (0.0001, 1e-6, 0.8, True),\n",
    "        (0.0001, 1e-6, 0.9, True), (0.001, 1e-6, 0.2, True),\n",
    "        (0.001, 1e-6, 0.4, True), (0.001, 1e-6, 0.6, True), \n",
    "        (0.001, 1e-6, 0.8, True), (0.001, 1e-6, 0.9, True),\n",
    "        (0.01, 1e-6, 0.2, True), (0.01, 1e-6, 0.4, True),\n",
    "        (0.01, 1e-6, 0.6, True), (0.01, 1e-6, 0.8, True),\n",
    "        (0.01, 1e-6, 0.9, True), (0.1, 1e-6, 0.2, True),\n",
    "        (0.1, 1e-6, 0.4, True), (0.1, 1e-6, 0.6, True), \n",
    "        (0.1, 1e-6, 0.8, True), (0.1, 1e-6, 0.9, True)]\n",
    "for l, d, m, n in sgdl:\n",
    "    sgd = optimizers.SGD(lr=l,decay=d,momentum=m,nesterov=n)\n",
    "    model_pointnet.compile(\n",
    "        optimizer=sgd,\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "        )\n",
    "    print(\"hyperparams:\", l, \",\", d, \",\", m, \",\", n)\n",
    "    history = model_pointnet.fit_generator(\n",
    "        generator_pointclouds_train,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data=generator_pointclouds_validate,\n",
    "        validation_steps=validation_steps\n",
    "        )\n",
    "    \n",
    "    #model_pointnet.predict_generator(generator_pointclouds_test,steps=10)\n",
    "    #print(model_pointnet.metrics_names)\n",
    "    #model_pointnet.evaluate_generator(generator_pointclouds_test,steps=100,use_multiprocessing=True)\n",
    "    \n",
    "    output_path = \".\"\n",
    "    modelutils.save_model_and_history(output_path, model_pointnet, history, training_details, \"pointnet-original\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving everything.\n",
    "\n",
    "This saves the model, its history and the training-details to some output directory. The created artifacts can later be uses in order to compare different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
